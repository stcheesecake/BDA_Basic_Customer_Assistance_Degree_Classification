#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
model.py
- CatBoostClassifier í•™ìŠµ/í‰ê°€/ì €ì¥/ì¶”ë¡ 
- ì„ê³„ê°’ ì •ì±…:
    - THRESHOLDê°€ ìˆ«ìë©´: ê·¸ ê°’ì„ ê³ ì • ì‚¬ìš© (policy: "fixed")
    - THRESHOLDê°€ Noneì´ë©´: Balanced Accuracy(= (acc0 + acc1)/2) ìµœëŒ€í™”ë¡œ íƒìƒ‰ (policy: "balacc")
- ê¸°ë³¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°ëŠ” ì „ì—­ DEFAULT_PARAMSë§Œ ì‚¬ìš© (best_params.json ì‚¬ìš© ì œê±°)
- í•™ìŠµ CSV ê¸°ë³¸: data/preprocessed_train_oof.csv
- í…ŒìŠ¤íŠ¸ CSVê°€ ì£¼ì–´ì§€ë©´ results/YYYYMMDD_submission.csv ë¡œ ì €ì¥
"""

import os
import json
import argparse
import datetime
from typing import Dict, List, Optional, Tuple

import numpy as np
import pandas as pd
from catboost import CatBoostClassifier, Pool
from sklearn.metrics import (
    f1_score, roc_auc_score, precision_score, recall_score,
    confusion_matrix
)
from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OrdinalEncoder
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from imblearn.over_sampling import SMOTENC
from joblib import dump, load
from sklearn.neighbors import NearestNeighbors

# ----------------------------- ì „ì—­ DEFAULT -----------------------------
DEFAULT_PARAMS = dict(
    iterations=2400,           # param_iterations
    learning_rate=0.1,        # param_learning_rate
    depth=9,                   # param_depth
    l2_leaf_reg=17.0,           # param_l2_leaf_reg
    border_count=80,          # param_border_count
    random_strength=1.7,       # param_random_strength
    bagging_temperature=0.25,   # param_bagging_temperature
    loss_function="Logloss",
    eval_metric="F1",
    od_type="Iter",
    od_wait=100,
    boosting_type="Ordered",
    task_type="GPU",
    random_seed=42,
    verbose=False,
    _use_smote_nc=True,  # ê¸°ë³¸ì ìœ¼ë¡œ SMOTE-NC ì‚¬ìš©
    _smote_sampling=0.85,  # ì†Œìˆ˜:ë‹¤ìˆ˜ ë¹„ìœ¨ ëª©í‘œ (ì˜ˆ: 0.9 â‰ˆ 9:10)
    _smote_k=6,  # k_neighbors
)

# ======= ì„ê³„ê°’ ì œì–´ =======
# ìˆ«ì(ì˜ˆ: 0.52)ë¡œ ì§€ì •í•˜ë©´ ê·¸ ì„ê³„ê°’ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©
# Noneì´ë©´ Balanced Accuracy ìµœëŒ€í™”ë¡œ ì„ê³„ê°’ íƒìƒ‰
THRESHOLD: Optional[float] = 0.46

# ======= EVAL POLICY (íƒìƒ‰ ì‹œì—ë§Œ ì‚¬ìš©) =======
THRESHOLD_STRATEGY = "balacc"       # ì„ê³„ê°’ ì„ íƒ ì •ì±…(íƒìƒ‰ ì‹œ): Balanced Accuracy
THRESHOLD_GRID = np.linspace(0.05, 0.95, 181)
SCORE_KEY = "balacc"                # ë¡œê·¸ì˜ ëŒ€í‘œ ì ìˆ˜ í‚¤

# ----------------------------- argparse -----------------------------
def parse_args():
    ap = argparse.ArgumentParser()
    ap.add_argument("--train_path", default="data/preprocessed_train_oof.csv",
                    help="í•™ìŠµ CSV ê²½ë¡œ(ê¸°ë³¸: data/preprocessed_train_oof.csv)")
    ap.add_argument("--test_path", default="data/preprocessed_test_oof.csv",
                    help="í…ŒìŠ¤íŠ¸ CSV ê²½ë¡œ(ê¸°ë³¸: None). ì§€ì • ì‹œ submission ìƒì„±")
    ap.add_argument("--target", default="withdrawal", help="íƒ€ê¹ƒ ì»¬ëŸ¼ëª…(ê¸°ë³¸: withdrawal)")
    ap.add_argument("--save_dir", default="results/optimization", help="ëª¨ë¸/ë¡œê·¸ ì €ì¥ í´ë”")
    ap.add_argument("--valid_size", type=float, default=0.2, help="ê²€ì¦ ë¹„ìœ¨(ê¸°ë³¸ 0.2)")
    ap.add_argument("--seed", type=int, default=42, help="ì¬í˜„ì„± ì‹œë“œ")
    ap.add_argument("--deterministic", action="store_true", help="ê²°ì •ë¡  ëª¨ë“œ(thread_count=1 ê¶Œì¥)")
    ap.add_argument("--use_smote_nc", action="store_true", help="Train splitì—ë§Œ SMOTE-NC ì ìš©")
    ap.add_argument("--smote_sampling", type=float, default=0.9, help="SMOTENC sampling_strategy (e.g., 0.8~1.0)")
    ap.add_argument("--smote_k", type=int, default=5, help="SMOTENC k_neighbors")
    return ap.parse_args()

# ----------------------------- utils -----------------------------
def _ensure_dir(p: str) -> None:
    os.makedirs(p, exist_ok=True)

def infer_cat_feature_indices(df: pd.DataFrame) -> List[int]:
    """OOF í™•ë¥ (*_oof_prob)ì€ ì œì™¸í•˜ê³ , object/categoryë§Œ cat_featuresë¡œ ì§€ì •"""
    oof_cols = [c for c in df.columns if c.endswith("_oof_prob")]
    cat_cols = df.select_dtypes(include=["object", "category"]).columns.tolist()
    cat_cols = [c for c in cat_cols if c not in oof_cols]
    return [df.columns.get_loc(c) for c in cat_cols]

def compute_class_weights(y: pd.Series) -> List[float]:
    c0 = int((y == 0).sum())
    c1 = int((y == 1).sum())
    if c0 == 0 or c1 == 0:
        return [1.0, 1.0]
    return [1.0, c0 / c1]

def now_tag() -> str:
    return datetime.datetime.now().strftime("%Y%m%d")

def write_report_txt(path: str, params: Dict, thr: float, policy: str, metrics: Dict) -> None:
    lines = []
    lines.append("==== CatBoost Train Report ====")
    lines.append("")
    lines.append("[Hyperparameters]")
    for k in sorted(params.keys()):
        lines.append(f"{k}: {params[k]}")
    lines.append("")
    lines.append(f"[Threshold] {thr:.6f} (policy: {policy})")
    lines.append("")
    lines.append("[Metrics]")
    for k in ["f1", "auc", "precision", "recall", "acc0", "acc1", "balacc", "youden", "score"]:
        if k in metrics:
            v = metrics[k]
            try:
                lines.append(f"{k}: {v:.6f}")
            except Exception:
                lines.append(f"{k}: {v}")
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w", encoding="utf-8") as f:
        f.write("\n".join(lines))
    print(f"[Saved] report txt -> {path}")

# ----------------------- ì„ê³„ê°’(BalAcc) ìœ í‹¸ -----------------------
def _rates_at(y_true: np.ndarray, prob: np.ndarray, thr: float) -> Dict[str, float]:
    pred = (prob >= thr).astype(int)
    tn, fp, fn, tp = confusion_matrix(y_true, pred).ravel()
    acc1 = tp / (tp + fn) if (tp + fn) else 0.0  # ì¬í˜„ìœ¨ TPR
    acc0 = tn / (tn + fp) if (tn + fp) else 0.0  # íŠ¹ì´ë„ TNR
    balacc = 0.5 * (acc0 + acc1)
    youden = acc1 - (1.0 - acc0)
    f1 = f1_score(y_true, pred) if (tp + fp > 0 and tp + fn > 0) else 0.0
    return dict(acc0=acc0, acc1=acc1, balacc=balacc, youden=youden, f1=f1)

def find_best_threshold_balacc(y_true: np.ndarray,
                               prob: np.ndarray,
                               grid: Optional[np.ndarray] = None) -> Tuple[float, float]:
    if grid is None:
        grid = THRESHOLD_GRID
    best_thr, best_score = 0.5, -1.0
    for t in grid:
        score = _rates_at(y_true, prob, t)["balacc"]
        if score > best_score:
            best_score, best_thr = score, t
    return float(best_thr), float(best_score)

def metrics_from_cm(y_true: np.ndarray, y_pred: np.ndarray, prob: Optional[np.ndarray] = None) -> Dict:
    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()
    acc0 = tn / (tn + fp) if (tn + fp) > 0 else 0.0
    acc1 = tp / (tp + fn) if (tp + fn) > 0 else 0.0
    balacc = 0.5 * (acc0 + acc1)
    youden = acc1 - (1.0 - acc0)
    res = dict(
        f1=f1_score(y_true, y_pred),
        precision=precision_score(y_true, y_pred),
        recall=recall_score(y_true, y_pred),
        acc0=acc0,
        acc1=acc1,
        balacc=balacc,
        youden=youden
    )
    if prob is not None:
        try:
            res["auc"] = roc_auc_score(y_true, prob)
        except Exception:
            res["auc"] = float("nan")
    return res

def build_preprocessor(num_cols, cat_cols):
    cat_pipe = Pipeline(steps=[
        ("imp", SimpleImputer(strategy="most_frequent")),
        ("ord", OrdinalEncoder(handle_unknown="use_encoded_value", unknown_value=-1)),
    ])
    num_pipe = Pipeline(steps=[
        ("imp", SimpleImputer(strategy="median")),
    ])
    return ColumnTransformer(
        transformers=[("num", num_pipe, num_cols), ("cat", cat_pipe, cat_cols)],
        remainder="drop"
    )

# ----------------------- core training API -----------------------
def train_and_eval(
    train_path: str = "data/preprocessed_train_oof.csv",
    params: Optional[Dict] = None,  # ì™¸ë¶€ì—ì„œ dictë¡œ ë®ì–´ì”Œìš°ê³  ì‹¶ì„ ë•Œë§Œ ì‚¬ìš©
    target_col: str = "withdrawal",
    save_dir: str = "results/optimization",
    valid_size: float = 0.2,
    seed: int = 42,
    deterministic: bool = False,
    produce_artifacts: bool = True,  # íŒŒì¼ ì €ì¥/ìƒì„± on/off
    quiet: bool = False,             # ì½˜ì†” ì¶œë ¥ on/off
) -> Dict:
    """
    ë‹¨ì¼ í™€ë“œì•„ì›ƒ(valid_size)ë¡œ í•™ìŠµ/í‰ê°€.
    ë°˜í™˜: {'model_path','threshold','metrics','params','cat_idx','score'}
    """
    assert os.path.exists(train_path), f"train csv not found: {train_path}"
    _ensure_dir(save_dir)

    df = pd.read_csv(train_path)
    assert target_col in df.columns, f"target '{target_col}' not in {train_path}"

    y = df[target_col].astype(int)
    X = df.drop(columns=[target_col])

    # cat_features ì¶”ì • (OOF í™•ë¥  ì œì™¸ + object/categoryë§Œ)
    cat_idx = infer_cat_feature_indices(X)

    # íŒŒë¼ë¯¸í„°: ì „ì—­ DEFAULT_PARAMSë§Œ ì‚¬ìš©, í•„ìš” ì‹œ ì¸ìë¡œ ì „ë‹¬ëœ paramsë¡œë§Œ ë®ì–´ì“°ê¸°
    p = DEFAULT_PARAMS.copy()
    if params is not None:
        p.update(params)

    # ê²°ì •ë¡  ì˜µì…˜
    if deterministic:
        p["deterministic"] = True
        p["thread_count"] = 1

    # class_weights ìë™ ë³´ì •(ì—†ì„ ë•Œë§Œ)
    if "class_weights" not in p and "auto_class_weights" not in p:
        p["class_weights"] = compute_class_weights(y)

    # split
    X_tr, X_va, y_tr, y_va = train_test_split(
        X, y, test_size=valid_size, stratify=y, random_state=seed
    )

    # â”€â”€ SMOTE-NC ë¶„ê¸° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    use_smote_nc = bool(p.pop("_use_smote_nc", False))
    smote_sampling = float(p.pop("_smote_sampling", 0.9))
    smote_k = int(p.pop("_smote_k", 5))

    pre = None  # (SMOTE ê²½ë¡œì—ì„œë§Œ ì‚¬ìš©)

    if use_smote_nc:
        # (a) ì›ë³¸ DF ê¸°ì¤€ ì—´ ë¶„ë¦¬
        cat_cols = X.select_dtypes(include=["object", "bool", "category"]).columns.tolist()
        num_cols = [c for c in X.columns if c not in cat_cols]

        # (b) ì „ì²˜ë¦¬: Trainì— fit, Validì— transform
        cat_pipe = Pipeline(steps=[
            ("imp", SimpleImputer(strategy="most_frequent")),
            ("ord", OrdinalEncoder(handle_unknown="use_encoded_value", unknown_value=-1)),
        ])
        num_pipe = Pipeline(steps=[
            ("imp", SimpleImputer(strategy="median")),
        ])
        pre = ColumnTransformer(
            transformers=[("num", num_pipe, num_cols), ("cat", cat_pipe, cat_cols)],
            remainder="drop"
        )
        X_tr_t = pre.fit_transform(X_tr)
        X_va_t = pre.transform(X_va)

        # (c) ë³€í™˜ ê²°ê³¼ì—ì„œ ë²”ì£¼í˜• ì¸ë±ìŠ¤([num..., cat...])
        n_num, n_cat = len(num_cols), len(cat_cols)
        cat_idx_out = list(range(n_num, n_num + n_cat))

        # (d) Trainì—ë§Œ SMOTENC (ëˆ„ìˆ˜ ë°©ì§€)
        smote = SMOTENC(
            categorical_features=cat_idx_out,
            sampling_strategy=smote_sampling,
            k_neighbors=smote_k,
            random_state=seed,
        )
        X_tr_bal, y_tr_bal = smote.fit_resample(X_tr_t, y_tr)

        # (e) Pool (ì´ë¯¸ ìˆ«ìí™”ëìœ¼ë¯€ë¡œ cat_features ë¶ˆí•„ìš”)
        train_pool = Pool(X_tr_bal, y_tr_bal)
        valid_pool = Pool(X_va_t, y_va)
    else:
        # ê¸°ì¡´ ê²½ë¡œ: CatBoostê°€ ë²”ì£¼í˜• ì§ì ‘ ì²˜ë¦¬
        cat_idx = infer_cat_feature_indices(X)
        train_pool = Pool(X_tr, y_tr, cat_features=cat_idx)
        valid_pool = Pool(X_va, y_va, cat_features=cat_idx)

    # í•™ìŠµ
    model = CatBoostClassifier(**p)
    model.fit(train_pool, eval_set=valid_pool, verbose=p.get("verbose", False))

    # ì„ê³„ê°’: ì „ì—­ THRESHOLDê°€ ìˆ«ìë©´ ê³ ì • ì‚¬ìš©, ì•„ë‹ˆë©´ BalAcc ìµœëŒ€ íƒìƒ‰
    prob = model.predict_proba(valid_pool)[:, 1]
    if THRESHOLD is not None:
        thr = float(THRESHOLD)
        policy = "fixed"
    else:
        thr, _ = find_best_threshold_balacc(y_va.values, prob)
        policy = THRESHOLD_STRATEGY

    # ì§€í‘œ
    pred = (prob >= thr).astype(int)
    metrics = metrics_from_cm(y_va.values, pred, prob)
    metrics["score"] = metrics.get(SCORE_KEY, float("nan"))

    # ì €ì¥ë¬¼
    model_path = os.path.join(save_dir, "catboost_model.cbm")
    if produce_artifacts:
        model.save_model(model_path)
        try:
            if pre is not None:
                dump(pre, os.path.join(save_dir, "preprocessor.joblib"))
        except Exception:
            pass
        with open(os.path.join(save_dir, "best_threshold.json"), "w", encoding="utf-8") as f:
            json.dump({"best_threshold": thr, "policy": policy}, f, ensure_ascii=False, indent=2)
        with open(os.path.join(save_dir, "used_params.json"), "w", encoding="utf-8") as f:
            json.dump(p, f, ensure_ascii=False, indent=2)
        write_report_txt(os.path.join(save_dir, "metrics.txt"), p, thr, policy, metrics)

    # ì½˜ì†” ìš”ì•½
    if not quiet:
        print("\n==== Summary ====")
    if produce_artifacts:
        print(f"Model saved      : {model_path}")
    print(f"Threshold        : {thr:.4f} (policy: {policy})")
    for k in ["f1", "auc", "precision", "recall", "acc0", "acc1", "balacc", "youden", "score"]:
        if k in metrics:
            v = metrics[k]
            print(f"{k:>9}: {v:.4f}" if isinstance(v, (int, float)) else f"{k:>9}: {v}")

    return dict(
        model_path=model_path,
        threshold=thr,
        metrics=metrics,
        params=p,
        cat_idx=cat_idx,
        score=metrics["score"]
    )

# ----------------------------- inference -----------------------------
def infer_and_submit(
    model_path: str,
    threshold: float,
    test_path: str,
    target_col: str = "withdrawal",
    save_dir: str = "results",
    id_candidates: Tuple[str, ...] = ("ID", "id", "Id", "index")
) -> str:
    assert os.path.exists(model_path), f"model not found: {model_path}"
    assert os.path.exists(test_path), f"test csv not found: {test_path}"
    _ensure_dir(save_dir)

    model = CatBoostClassifier()
    model.load_model(model_path)

    test_df = pd.read_csv(test_path)
    X_test = test_df.copy()
    if target_col in X_test.columns:
        X_test = X_test.drop(columns=[target_col])

    pre_path = os.path.join(os.path.dirname(model_path), "preprocessor.joblib")
    if os.path.exists(pre_path):
        pre = load(pre_path)
        X_test_t = pre.transform(X_test)
        test_pool = Pool(X_test_t)  # numeric
    else:
        cat_idx = infer_cat_feature_indices(X_test)
        test_pool = Pool(X_test, cat_features=cat_idx)

    prob = model.predict_proba(test_pool)[:, 1]
    pred = (prob >= threshold).astype(int)

    # ID ì»¬ëŸ¼ ì¶”ì •/ìƒì„±
    id_col = None
    for c in id_candidates:
        if c in test_df.columns:
            id_col = c
            break
    if id_col is None:
        id_col = "ID"
        n = len(test_df)
        # ğŸ”§ sample_submission.csvì™€ ë™ì¼ í¬ë§·: TEST_0000 ~ TEST_0787
        test_df[id_col] = [f"TEST_{i:04d}" for i in range(n)]

    submit = pd.DataFrame({id_col: test_df[id_col], target_col: pred})
    out_path = os.path.join(save_dir, f"{now_tag()}_submission.csv")
    submit.to_csv(out_path, index=False)
    print(f"[Saved] submission -> {out_path}")
    return out_path

# ------------------------------- CLI --------------------------------
def main_cli():
    args = parse_args()
    out = train_and_eval(
        train_path=args.train_path,
        params=None,  # ì™¸ë¶€ì—ì„œ ë®ì–´ì“¸ í•„ìš”ê°€ ìˆìœ¼ë©´ dictë¡œ ì „ë‹¬
        target_col=args.target,
        save_dir=args.save_dir,
        valid_size=args.valid_size,
        seed=args.seed,
        deterministic=args.deterministic,
    )
    if args.test_path is not None and str(args.test_path).lower() != "none":
        infer_and_submit(
            model_path=out["model_path"],
            threshold=out["threshold"],
            test_path=args.test_path,
            target_col=args.target,
            save_dir="results"
        )

if __name__ == "__main__":
    main_cli()
