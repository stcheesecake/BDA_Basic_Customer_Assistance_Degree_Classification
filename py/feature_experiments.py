import pandas as pd
import numpy as np
import os
from datetime import datetime
from itertools import combinations
import optuna
optuna.logging.set_verbosity(optuna.logging.WARNING)
from tqdm import tqdm
import sys, os
from contextlib import contextmanager

@contextmanager
def suppress_output():
    with open(os.devnull, 'w') as fnull:
        old_stdout, old_stderr = sys.stdout, sys.stderr
        sys.stdout, sys.stderr = fnull, fnull
        try:
            yield
        finally:
            sys.stdout, sys.stderr = old_stdout, old_stderr

# ===================================================================
#                      ì‚¬ìš©ì ì„¤ì • ë³€ìˆ˜
# ===================================================================

# íƒìƒ‰ ë°©ì‹: 'grid' ë˜ëŠ” 'optuna'
SEARCHING_SWITCH = 'optuna'   # 'optuna' ë¡œ ë°”ê¿”ì„œ ì‹¤í–‰ ê°€ëŠ¥
USE_GPU = True
TRIALS = 2

# ì›ë³¸ ë°ì´í„° ê²½ë¡œ (ìˆ˜ì •í•˜ì§€ ì•ŠìŒ)
BASE_FEATURED_DATASET = 'data/total_train.csv'

# ì‹¤í—˜í•  ëª¨ë¸ ì´ë¦„ (ìˆ˜ì •í•˜ì§€ ì•ŠìŒ)
MODEL = 'tabnet'  # 'catboost', 'xgboost' ë“±ìœ¼ë¡œ ë³€ê²½í•˜ì—¬ ì‚¬ìš©

# ì‹¤í—˜ì„ ë°˜ë³µí•  ì‹œë“œ(seed) ëª©ë¡
SEEDS = [45]
best_f1 = 0.0  # ìˆ˜ì • x

# ì‹¤í—˜í•  ìƒˆë¡œìš´ í”¼ì²˜ í›„ë³´ ì „ì²´ ëª©ë¡ì…ë‹ˆë‹¤.
ALL_NEW_FEATURES = [
    'is_older_group', 'older_and_member', 'is_low_frequency',
    'vip_inactive', 'new_inactive',
    'is_long_contract', 'is_high_payment_interval', 'is_high_interaction',
    'freq_per_tenure', 'interaction_per_freq', 'payment_per_freq',
    'short_tenure_high_interval', 'older_low_contract', 'vip_low_interaction',
    'interaction_rate', 'contract_ratio', 'payment_freq_alignment',
    'renewal_pressure', 'subscription_code', 'gender_age_group', 'usage_cluster'
]
# ===================================================================

# [ì¶”ê°€] MODEL ë³€ìˆ˜ê°’ì— ë”°ë¼ ì‹¤ì œ ì‚¬ìš©í•  ëª¨ë¸ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë™ì ìœ¼ë¡œ import
if MODEL == 'lightgbm':
    import lightgbm_classifier as model_module
elif MODEL == 'catboost':
    import catboost_classifier as model_module
elif MODEL == 'xgboost':
    import xgboost_classifier as model_module
elif MODEL == 'tabnet':
    import tabnet_classifier as model_module
else:
    raise ValueError("ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ì…ë‹ˆë‹¤")


def run_and_log_experiment(model_module, dataset_path, features_to_include, seeds, log_file_path):
    """
    ì§€ì •ëœ í”¼ì²˜ ì¡°í•©ìœ¼ë¡œ ì‹¤í—˜ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ CSV íŒŒì¼ì— ê¸°ë¡í•©ë‹ˆë‹¤.
    """
    if not features_to_include:
        included_features_str = 'Original_Baseline'
    else:
        included_features_str = ', '.join(features_to_include)

    f1_scores, accuracy_scores = [], []
    full_df = pd.read_csv(dataset_path)

    features_to_exclude = [f for f in ALL_NEW_FEATURES if f not in features_to_include]
    existing_features_to_drop = [col for col in features_to_exclude if col in full_df.columns]
    df = full_df.drop(columns=existing_features_to_drop)

    temp_train_path = 'temp_train_for_experiment.csv'
    df.to_csv(temp_train_path, index=False)

    for seed in seeds:
        with suppress_output():  # ğŸ‘ˆ ì—¬ê¸°ì„œ ì¶œë ¥ ì „ë¶€ ì°¨ë‹¨
            result = model_module.train_and_eval(
                train_path=temp_train_path,
                seed=seed,
                produce_artifacts=False,
                use_gpu = USE_GPU
            )
        f1_scores.append(result['metrics']['f1_macro'])
        accuracy_scores.append(result['metrics']['accuracy'])

    os.remove(temp_train_path)

    mean_f1 = np.mean(f1_scores)
    mean_accuracy = np.mean(accuracy_scores)

    log_results(included_features_str, mean_f1, mean_accuracy, log_file_path)


def log_results(included_features_str, f1_macro, accuracy, log_file):
    """
    ì‹¤í—˜ ê²°ê³¼ë¥¼ CSV íŒŒì¼ì— í•œ ì¤„ ì¶”ê°€í•©ë‹ˆë‹¤.
    """
    new_log = pd.DataFrame({
        'TIMESTAMP': [datetime.now().strftime('%Y-%m-%d %H:%M:%S')],
        'í¬í•¨ëœ FEATURE': [included_features_str],
        'F1 MACRO': [f"{f1_macro:.4f}"],
        'ACCURACY': [f"{accuracy:.4f}"]
    })

    if not os.path.exists(log_file):
        new_log.to_csv(log_file, index=False, encoding='utf-8-sig')
    else:
        new_log.to_csv(log_file, mode='a', header=False, index=False, encoding='utf-8-sig')


# --- ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„ ---
if __name__ == "__main__":
    output_dir = 'results/eda/feature_engineering'
    os.makedirs(output_dir, exist_ok=True)
    timestamp = datetime.now().strftime('%y%m%d_%H%M%S')
    log_file_path = os.path.join(output_dir, f"{timestamp}_{MODEL}_feature_experiments.csv")
    print(f"ì‹¤í—˜ ê²°ê³¼ëŠ” ë‹¤ìŒ íŒŒì¼ì— ì €ì¥ë©ë‹ˆë‹¤: {log_file_path}")

    if SEARCHING_SWITCH == 'grid':
        all_combinations = [[]]
        for r in range(1, len(ALL_NEW_FEATURES) + 1):
            for combo in combinations(ALL_NEW_FEATURES, r):
                all_combinations.append(list(combo))

        best_f1 = 0.0
        with tqdm(total=len(all_combinations), desc="Grid Search") as pbar:
            for features in all_combinations:
                run_and_log_experiment(
                    model_module=model_module,
                    dataset_path=BASE_FEATURED_DATASET,
                    features_to_include=features,
                    seeds=SEEDS,
                    log_file_path=log_file_path
                )
                last_f1 = float(pd.read_csv(log_file_path).iloc[-1]["F1 MACRO"])
                if last_f1 > best_f1:
                    best_f1 = last_f1
                pbar.set_postfix_str(f"BEST F1: {best_f1:.4f}")
                pbar.update(1)

    elif SEARCHING_SWITCH == 'optuna':
        best_f1 = 0.0


        def objective(trial):
            global best_f1  # ì „ì—­ best_f1 ì‚¬ìš©
            selected = []
            for feat in ALL_NEW_FEATURES:
                use_feat = trial.suggest_int(f"use_{feat}", 0, 1)
                if use_feat == 1:
                    selected.append(feat)

            run_and_log_experiment(
                model_module=model_module,
                dataset_path=BASE_FEATURED_DATASET,
                features_to_include=selected,
                seeds=SEEDS,
                log_file_path=log_file_path
            )

            last_f1 = float(pd.read_csv(log_file_path).iloc[-1]["F1 MACRO"])

            if last_f1 > best_f1:  # ğŸ”¥ ìµœê³  ì„±ëŠ¥ ê°±ì‹ 
                best_f1 = last_f1

            feat_str = ",".join(selected) if selected else "baseline"
            pbar.set_postfix_str(f"BEST F1: {best_f1:.4f} | ì‚¬ìš©ëœ feature: {feat_str}")

            return last_f1


        study = optuna.create_study(direction="maximize")
        with tqdm(total=TRIALS, desc="Optuna") as pbar:
            def wrapped_objective(trial):
                val = objective(trial)
                pbar.update(1)
                return val


            study.optimize(wrapped_objective, n_trials=TRIALS)

        print("Optuna íƒìƒ‰ ì™„ë£Œ")
        print("Best params:", study.best_params)
        print("Best score:", study.best_value)

    print("\n\n===== ëª¨ë“  íƒìƒ‰ ì™„ë£Œ =====")
    print(f"ì „ì²´ ê²°ê³¼ëŠ” '{log_file_path}'ë¥¼ í™•ì¸í•˜ì„¸ìš”.")